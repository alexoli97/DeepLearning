{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EajZS7CvENKr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ],
      "metadata": {
        "id": "KZn1t0PWEXAN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "        [transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "trainset_big = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainset = torch.utils.data.Subset(trainset_big,list(range(10000)))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "val_set = torch.utils.data.Subset(trainset_big,list(range(10000, 20000)))\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDVfadT2EZ-4",
        "outputId": "31829558-7d28-4164-d7df-768878215332"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 15798793.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
        "    best_model = model\n",
        "    best_loss = 100\n",
        "    for epoch in range(num_epochs):\n",
        "        tr_correct = 0\n",
        "        tr_total = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        for batch_nr, (data, labels) in enumerate(train_loader):\n",
        "            \n",
        "            print(\"Epoch: \",epoch,\"Batch: \",batch_nr)\n",
        "            # calculate prediction according to our model\n",
        "            data = data.cuda()\n",
        "            labels = labels.cuda()\n",
        "            prediction = model.forward(data)\n",
        "            # Calculate the loss of the prediction by comparing to the expected output\n",
        "            loss = criterion(prediction, labels)\n",
        "            \n",
        "            # Backpropagate the loss through the network to find the gradients of all parameters\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters along their gradients\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Clear stored gradient values\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # calculate accuracy\n",
        "            for i in range(len(data)):    \n",
        "                guess = torch.argmax(prediction[i])\n",
        "                if(guess.item() == labels[i]):\n",
        "                    tr_correct+=1\n",
        "                tr_total +=1\n",
        "\n",
        "\n",
        "\n",
        "        for batch_nr, (data, labels) in enumerate(val_loader):\n",
        "            data = data.cuda()  \n",
        "            labels = labels.cuda()  \n",
        "            prediction = model.forward(data)\n",
        "            \n",
        "            # Calculate the loss of the prediction by comparing to the expected output\n",
        "            loss = criterion(prediction, labels)\n",
        "\n",
        "            if(loss < best_loss):\n",
        "                best_loss = loss\n",
        "                best_model = model\n",
        "\n",
        "            # calculate accuracy\n",
        "            for i in range(len(data)):    \n",
        "                guess = torch.argmax(prediction[i])\n",
        "                if(guess.item() == labels[i]):\n",
        "                    val_correct+=1\n",
        "                val_total +=1\n",
        "\n",
        "    # print accuracy\n",
        "    tr_accuracy = tr_correct/tr_total\n",
        "    val_accuracy = val_correct/val_total\n",
        "    print(f'Training accuracy:   {str(100*tr_accuracy)[:4]}%.')\n",
        "    print(f'Validation accuracy: {str(100*val_accuracy)[:4]}%.')\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "slKzgwQIEe5K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    for batch_nr, (data, labels) in enumerate(test_loader):\n",
        "\n",
        "        data = data.cuda()  \n",
        "        labels = labels.cuda()  \n",
        "        prediction = model.forward(data)\n",
        "        \n",
        "        # calculate accuracy\n",
        "        for i in range(len(data)):    \n",
        "            guess = torch.argmax(prediction[i])\n",
        "            if(guess.item() == labels[i]):\n",
        "                val_correct+=1\n",
        "            val_total +=1\n",
        "\n",
        "    # primt accuracy\n",
        "    val_accuracy = val_correct/val_total\n",
        "    print(f'Test accuracy: {str(100*val_accuracy)[:4]}%.')"
      ],
      "metadata": {
        "id": "IFeAmg5TEg-H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexNet_fineTuning = torchvision.models.alexnet(pretrained=True)\n",
        "alexNet_fineTuning.classifier[6] = nn.Linear(4096,10)\n",
        "\n",
        "# alexNet_fineTuning.eval"
      ],
      "metadata": {
        "id": "7B-C6kczEiM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fb2110-dd8e-421e-d595-25c912992a1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:00<00:00, 349MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define for the optimization algorithm which parameters we want to update during training\n",
        "\n",
        "# Define our loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define our optimizer\n",
        "optimizer = torch.optim.Adam(alexNet_fineTuning.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "fOsDKUbAEjqf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexNet_fineTuning = alexNet_fineTuning.cuda()"
      ],
      "metadata": {
        "id": "BFG2TyhNm_o9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run the training step\n",
        "train_model(alexNet_fineTuning,criterion,optimizer,trainloader,val_loader,num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oQR_iM3ElQX",
        "outputId": "85c9f958-7d89-4626-ec4f-e88db2b298b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0 Batch:  0\n",
            "Epoch:  0 Batch:  1\n",
            "Epoch:  0 Batch:  2\n",
            "Epoch:  0 Batch:  3\n",
            "Epoch:  0 Batch:  4\n",
            "Epoch:  0 Batch:  5\n",
            "Epoch:  0 Batch:  6\n",
            "Epoch:  0 Batch:  7\n",
            "Epoch:  0 Batch:  8\n",
            "Epoch:  0 Batch:  9\n",
            "Epoch:  0 Batch:  10\n",
            "Epoch:  0 Batch:  11\n",
            "Epoch:  0 Batch:  12\n",
            "Epoch:  0 Batch:  13\n",
            "Epoch:  0 Batch:  14\n",
            "Epoch:  0 Batch:  15\n",
            "Epoch:  0 Batch:  16\n",
            "Epoch:  0 Batch:  17\n",
            "Epoch:  0 Batch:  18\n",
            "Epoch:  0 Batch:  19\n",
            "Epoch:  1 Batch:  0\n",
            "Epoch:  1 Batch:  1\n",
            "Epoch:  1 Batch:  2\n",
            "Epoch:  1 Batch:  3\n",
            "Epoch:  1 Batch:  4\n",
            "Epoch:  1 Batch:  5\n",
            "Epoch:  1 Batch:  6\n",
            "Epoch:  1 Batch:  7\n",
            "Epoch:  1 Batch:  8\n",
            "Epoch:  1 Batch:  9\n",
            "Epoch:  1 Batch:  10\n",
            "Epoch:  1 Batch:  11\n",
            "Epoch:  1 Batch:  12\n",
            "Epoch:  1 Batch:  13\n",
            "Epoch:  1 Batch:  14\n",
            "Epoch:  1 Batch:  15\n",
            "Epoch:  1 Batch:  16\n",
            "Epoch:  1 Batch:  17\n",
            "Epoch:  1 Batch:  18\n",
            "Epoch:  1 Batch:  19\n",
            "Epoch:  2 Batch:  0\n",
            "Epoch:  2 Batch:  1\n",
            "Epoch:  2 Batch:  2\n",
            "Epoch:  2 Batch:  3\n",
            "Epoch:  2 Batch:  4\n",
            "Epoch:  2 Batch:  5\n",
            "Epoch:  2 Batch:  6\n",
            "Epoch:  2 Batch:  7\n",
            "Epoch:  2 Batch:  8\n",
            "Epoch:  2 Batch:  9\n",
            "Epoch:  2 Batch:  10\n",
            "Epoch:  2 Batch:  11\n",
            "Epoch:  2 Batch:  12\n",
            "Epoch:  2 Batch:  13\n",
            "Epoch:  2 Batch:  14\n",
            "Epoch:  2 Batch:  15\n",
            "Epoch:  2 Batch:  16\n",
            "Epoch:  2 Batch:  17\n",
            "Epoch:  2 Batch:  18\n",
            "Epoch:  2 Batch:  19\n",
            "Epoch:  3 Batch:  0\n",
            "Epoch:  3 Batch:  1\n",
            "Epoch:  3 Batch:  2\n",
            "Epoch:  3 Batch:  3\n",
            "Epoch:  3 Batch:  4\n",
            "Epoch:  3 Batch:  5\n",
            "Epoch:  3 Batch:  6\n",
            "Epoch:  3 Batch:  7\n",
            "Epoch:  3 Batch:  8\n",
            "Epoch:  3 Batch:  9\n",
            "Epoch:  3 Batch:  10\n",
            "Epoch:  3 Batch:  11\n",
            "Epoch:  3 Batch:  12\n",
            "Epoch:  3 Batch:  13\n",
            "Epoch:  3 Batch:  14\n",
            "Epoch:  3 Batch:  15\n",
            "Epoch:  3 Batch:  16\n",
            "Epoch:  3 Batch:  17\n",
            "Epoch:  3 Batch:  18\n",
            "Epoch:  3 Batch:  19\n",
            "Epoch:  4 Batch:  0\n",
            "Epoch:  4 Batch:  1\n",
            "Epoch:  4 Batch:  2\n",
            "Epoch:  4 Batch:  3\n",
            "Epoch:  4 Batch:  4\n",
            "Epoch:  4 Batch:  5\n",
            "Epoch:  4 Batch:  6\n",
            "Epoch:  4 Batch:  7\n",
            "Epoch:  4 Batch:  8\n",
            "Epoch:  4 Batch:  9\n",
            "Epoch:  4 Batch:  10\n",
            "Epoch:  4 Batch:  11\n",
            "Epoch:  4 Batch:  12\n",
            "Epoch:  4 Batch:  13\n",
            "Epoch:  4 Batch:  14\n",
            "Epoch:  4 Batch:  15\n",
            "Epoch:  4 Batch:  16\n",
            "Epoch:  4 Batch:  17\n",
            "Epoch:  4 Batch:  18\n",
            "Epoch:  4 Batch:  19\n",
            "Epoch:  5 Batch:  0\n",
            "Epoch:  5 Batch:  1\n",
            "Epoch:  5 Batch:  2\n",
            "Epoch:  5 Batch:  3\n",
            "Epoch:  5 Batch:  4\n",
            "Epoch:  5 Batch:  5\n",
            "Epoch:  5 Batch:  6\n",
            "Epoch:  5 Batch:  7\n",
            "Epoch:  5 Batch:  8\n",
            "Epoch:  5 Batch:  9\n",
            "Epoch:  5 Batch:  10\n",
            "Epoch:  5 Batch:  11\n",
            "Epoch:  5 Batch:  12\n",
            "Epoch:  5 Batch:  13\n",
            "Epoch:  5 Batch:  14\n",
            "Epoch:  5 Batch:  15\n",
            "Epoch:  5 Batch:  16\n",
            "Epoch:  5 Batch:  17\n",
            "Epoch:  5 Batch:  18\n",
            "Epoch:  5 Batch:  19\n",
            "Epoch:  6 Batch:  0\n",
            "Epoch:  6 Batch:  1\n",
            "Epoch:  6 Batch:  2\n",
            "Epoch:  6 Batch:  3\n",
            "Epoch:  6 Batch:  4\n",
            "Epoch:  6 Batch:  5\n",
            "Epoch:  6 Batch:  6\n",
            "Epoch:  6 Batch:  7\n",
            "Epoch:  6 Batch:  8\n",
            "Epoch:  6 Batch:  9\n",
            "Epoch:  6 Batch:  10\n",
            "Epoch:  6 Batch:  11\n",
            "Epoch:  6 Batch:  12\n",
            "Epoch:  6 Batch:  13\n",
            "Epoch:  6 Batch:  14\n",
            "Epoch:  6 Batch:  15\n",
            "Epoch:  6 Batch:  16\n",
            "Epoch:  6 Batch:  17\n",
            "Epoch:  6 Batch:  18\n",
            "Epoch:  6 Batch:  19\n",
            "Epoch:  7 Batch:  0\n",
            "Epoch:  7 Batch:  1\n",
            "Epoch:  7 Batch:  2\n",
            "Epoch:  7 Batch:  3\n",
            "Epoch:  7 Batch:  4\n",
            "Epoch:  7 Batch:  5\n",
            "Epoch:  7 Batch:  6\n",
            "Epoch:  7 Batch:  7\n",
            "Epoch:  7 Batch:  8\n",
            "Epoch:  7 Batch:  9\n",
            "Epoch:  7 Batch:  10\n",
            "Epoch:  7 Batch:  11\n",
            "Epoch:  7 Batch:  12\n",
            "Epoch:  7 Batch:  13\n",
            "Epoch:  7 Batch:  14\n",
            "Epoch:  7 Batch:  15\n",
            "Epoch:  7 Batch:  16\n",
            "Epoch:  7 Batch:  17\n",
            "Epoch:  7 Batch:  18\n",
            "Epoch:  7 Batch:  19\n",
            "Epoch:  8 Batch:  0\n",
            "Epoch:  8 Batch:  1\n",
            "Epoch:  8 Batch:  2\n",
            "Epoch:  8 Batch:  3\n",
            "Epoch:  8 Batch:  4\n",
            "Epoch:  8 Batch:  5\n",
            "Epoch:  8 Batch:  6\n",
            "Epoch:  8 Batch:  7\n",
            "Epoch:  8 Batch:  8\n",
            "Epoch:  8 Batch:  9\n",
            "Epoch:  8 Batch:  10\n",
            "Epoch:  8 Batch:  11\n",
            "Epoch:  8 Batch:  12\n",
            "Epoch:  8 Batch:  13\n",
            "Epoch:  8 Batch:  14\n",
            "Epoch:  8 Batch:  15\n",
            "Epoch:  8 Batch:  16\n",
            "Epoch:  8 Batch:  17\n",
            "Epoch:  8 Batch:  18\n",
            "Epoch:  8 Batch:  19\n",
            "Epoch:  9 Batch:  0\n",
            "Epoch:  9 Batch:  1\n",
            "Epoch:  9 Batch:  2\n",
            "Epoch:  9 Batch:  3\n",
            "Epoch:  9 Batch:  4\n",
            "Epoch:  9 Batch:  5\n",
            "Epoch:  9 Batch:  6\n",
            "Epoch:  9 Batch:  7\n",
            "Epoch:  9 Batch:  8\n",
            "Epoch:  9 Batch:  9\n",
            "Epoch:  9 Batch:  10\n",
            "Epoch:  9 Batch:  11\n",
            "Epoch:  9 Batch:  12\n",
            "Epoch:  9 Batch:  13\n",
            "Epoch:  9 Batch:  14\n",
            "Epoch:  9 Batch:  15\n",
            "Epoch:  9 Batch:  16\n",
            "Epoch:  9 Batch:  17\n",
            "Epoch:  9 Batch:  18\n",
            "Epoch:  9 Batch:  19\n",
            "Training accuracy:   64.7%.\n",
            "Validation accuracy: 62.2%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define for the optimization algorithm which parameters we want to update during training\n",
        "alexNet_featureExtraction = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "for param in alexNet_featureExtraction.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "alexNet_featureExtraction.classifier[6] = nn.Linear(4096,10)\n",
        "# find the paramaters we want to update during training\n",
        "params_to_update = []\n",
        "for param in alexNet_featureExtraction.parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "for name, param in alexNet_featureExtraction.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print (name, param.data)\n",
        "\n",
        "# Define our loss function\n",
        "criterion_fe = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define our optimizer\n",
        "optimizer_fe = torch.optim.Adam(params_to_update, lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ned7_KxMGYoZ",
        "outputId": "f3c7e8a0-a519-455f-f53b-bc9a5f832e85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.6.weight tensor([[-0.0015, -0.0141,  0.0024,  ..., -0.0090, -0.0087, -0.0045],\n",
            "        [-0.0132,  0.0118,  0.0109,  ...,  0.0002,  0.0084, -0.0052],\n",
            "        [-0.0116, -0.0124,  0.0065,  ...,  0.0053,  0.0077,  0.0012],\n",
            "        ...,\n",
            "        [-0.0058, -0.0061, -0.0121,  ...,  0.0107,  0.0145, -0.0037],\n",
            "        [-0.0084, -0.0150,  0.0088,  ...,  0.0136, -0.0077,  0.0057],\n",
            "        [ 0.0032,  0.0083, -0.0051,  ..., -0.0114, -0.0068,  0.0012]])\n",
            "classifier.6.bias tensor([ 0.0072, -0.0004,  0.0048,  0.0009, -0.0081, -0.0046,  0.0025, -0.0065,\n",
            "         0.0095,  0.0036])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexNet_featureExtraction = alexNet_featureExtraction.cuda()"
      ],
      "metadata": {
        "id": "ssbcKUP2CCo8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the training step\n",
        "train_model(alexNet_featureExtraction,criterion_fe,optimizer_fe,trainloader,val_loader,num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKcgIXc5GaFe",
        "outputId": "b71c6e7c-72cd-445b-ba2f-814adc3597ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0 Batch:  0\n",
            "Epoch:  0 Batch:  1\n",
            "Epoch:  0 Batch:  2\n",
            "Epoch:  0 Batch:  3\n",
            "Epoch:  0 Batch:  4\n",
            "Epoch:  0 Batch:  5\n",
            "Epoch:  0 Batch:  6\n",
            "Epoch:  0 Batch:  7\n",
            "Epoch:  0 Batch:  8\n",
            "Epoch:  0 Batch:  9\n",
            "Epoch:  0 Batch:  10\n",
            "Epoch:  0 Batch:  11\n",
            "Epoch:  0 Batch:  12\n",
            "Epoch:  0 Batch:  13\n",
            "Epoch:  0 Batch:  14\n",
            "Epoch:  0 Batch:  15\n",
            "Epoch:  0 Batch:  16\n",
            "Epoch:  0 Batch:  17\n",
            "Epoch:  0 Batch:  18\n",
            "Epoch:  0 Batch:  19\n",
            "Epoch:  1 Batch:  0\n",
            "Epoch:  1 Batch:  1\n",
            "Epoch:  1 Batch:  2\n",
            "Epoch:  1 Batch:  3\n",
            "Epoch:  1 Batch:  4\n",
            "Epoch:  1 Batch:  5\n",
            "Epoch:  1 Batch:  6\n",
            "Epoch:  1 Batch:  7\n",
            "Epoch:  1 Batch:  8\n",
            "Epoch:  1 Batch:  9\n",
            "Epoch:  1 Batch:  10\n",
            "Epoch:  1 Batch:  11\n",
            "Epoch:  1 Batch:  12\n",
            "Epoch:  1 Batch:  13\n",
            "Epoch:  1 Batch:  14\n",
            "Epoch:  1 Batch:  15\n",
            "Epoch:  1 Batch:  16\n",
            "Epoch:  1 Batch:  17\n",
            "Epoch:  1 Batch:  18\n",
            "Epoch:  1 Batch:  19\n",
            "Epoch:  2 Batch:  0\n",
            "Epoch:  2 Batch:  1\n",
            "Epoch:  2 Batch:  2\n",
            "Epoch:  2 Batch:  3\n",
            "Epoch:  2 Batch:  4\n",
            "Epoch:  2 Batch:  5\n",
            "Epoch:  2 Batch:  6\n",
            "Epoch:  2 Batch:  7\n",
            "Epoch:  2 Batch:  8\n",
            "Epoch:  2 Batch:  9\n",
            "Epoch:  2 Batch:  10\n",
            "Epoch:  2 Batch:  11\n",
            "Epoch:  2 Batch:  12\n",
            "Epoch:  2 Batch:  13\n",
            "Epoch:  2 Batch:  14\n",
            "Epoch:  2 Batch:  15\n",
            "Epoch:  2 Batch:  16\n",
            "Epoch:  2 Batch:  17\n",
            "Epoch:  2 Batch:  18\n",
            "Epoch:  2 Batch:  19\n",
            "Epoch:  3 Batch:  0\n",
            "Epoch:  3 Batch:  1\n",
            "Epoch:  3 Batch:  2\n",
            "Epoch:  3 Batch:  3\n",
            "Epoch:  3 Batch:  4\n",
            "Epoch:  3 Batch:  5\n",
            "Epoch:  3 Batch:  6\n",
            "Epoch:  3 Batch:  7\n",
            "Epoch:  3 Batch:  8\n",
            "Epoch:  3 Batch:  9\n",
            "Epoch:  3 Batch:  10\n",
            "Epoch:  3 Batch:  11\n",
            "Epoch:  3 Batch:  12\n",
            "Epoch:  3 Batch:  13\n",
            "Epoch:  3 Batch:  14\n",
            "Epoch:  3 Batch:  15\n",
            "Epoch:  3 Batch:  16\n",
            "Epoch:  3 Batch:  17\n",
            "Epoch:  3 Batch:  18\n",
            "Epoch:  3 Batch:  19\n",
            "Epoch:  4 Batch:  0\n",
            "Epoch:  4 Batch:  1\n",
            "Epoch:  4 Batch:  2\n",
            "Epoch:  4 Batch:  3\n",
            "Epoch:  4 Batch:  4\n",
            "Epoch:  4 Batch:  5\n",
            "Epoch:  4 Batch:  6\n",
            "Epoch:  4 Batch:  7\n",
            "Epoch:  4 Batch:  8\n",
            "Epoch:  4 Batch:  9\n",
            "Epoch:  4 Batch:  10\n",
            "Epoch:  4 Batch:  11\n",
            "Epoch:  4 Batch:  12\n",
            "Epoch:  4 Batch:  13\n",
            "Epoch:  4 Batch:  14\n",
            "Epoch:  4 Batch:  15\n",
            "Epoch:  4 Batch:  16\n",
            "Epoch:  4 Batch:  17\n",
            "Epoch:  4 Batch:  18\n",
            "Epoch:  4 Batch:  19\n",
            "Epoch:  5 Batch:  0\n",
            "Epoch:  5 Batch:  1\n",
            "Epoch:  5 Batch:  2\n",
            "Epoch:  5 Batch:  3\n",
            "Epoch:  5 Batch:  4\n",
            "Epoch:  5 Batch:  5\n",
            "Epoch:  5 Batch:  6\n",
            "Epoch:  5 Batch:  7\n",
            "Epoch:  5 Batch:  8\n",
            "Epoch:  5 Batch:  9\n",
            "Epoch:  5 Batch:  10\n",
            "Epoch:  5 Batch:  11\n",
            "Epoch:  5 Batch:  12\n",
            "Epoch:  5 Batch:  13\n",
            "Epoch:  5 Batch:  14\n",
            "Epoch:  5 Batch:  15\n",
            "Epoch:  5 Batch:  16\n",
            "Epoch:  5 Batch:  17\n",
            "Epoch:  5 Batch:  18\n",
            "Epoch:  5 Batch:  19\n",
            "Epoch:  6 Batch:  0\n",
            "Epoch:  6 Batch:  1\n",
            "Epoch:  6 Batch:  2\n",
            "Epoch:  6 Batch:  3\n",
            "Epoch:  6 Batch:  4\n",
            "Epoch:  6 Batch:  5\n",
            "Epoch:  6 Batch:  6\n",
            "Epoch:  6 Batch:  7\n",
            "Epoch:  6 Batch:  8\n",
            "Epoch:  6 Batch:  9\n",
            "Epoch:  6 Batch:  10\n",
            "Epoch:  6 Batch:  11\n",
            "Epoch:  6 Batch:  12\n",
            "Epoch:  6 Batch:  13\n",
            "Epoch:  6 Batch:  14\n",
            "Epoch:  6 Batch:  15\n",
            "Epoch:  6 Batch:  16\n",
            "Epoch:  6 Batch:  17\n",
            "Epoch:  6 Batch:  18\n",
            "Epoch:  6 Batch:  19\n",
            "Epoch:  7 Batch:  0\n",
            "Epoch:  7 Batch:  1\n",
            "Epoch:  7 Batch:  2\n",
            "Epoch:  7 Batch:  3\n",
            "Epoch:  7 Batch:  4\n",
            "Epoch:  7 Batch:  5\n",
            "Epoch:  7 Batch:  6\n",
            "Epoch:  7 Batch:  7\n",
            "Epoch:  7 Batch:  8\n",
            "Epoch:  7 Batch:  9\n",
            "Epoch:  7 Batch:  10\n",
            "Epoch:  7 Batch:  11\n",
            "Epoch:  7 Batch:  12\n",
            "Epoch:  7 Batch:  13\n",
            "Epoch:  7 Batch:  14\n",
            "Epoch:  7 Batch:  15\n",
            "Epoch:  7 Batch:  16\n",
            "Epoch:  7 Batch:  17\n",
            "Epoch:  7 Batch:  18\n",
            "Epoch:  7 Batch:  19\n",
            "Epoch:  8 Batch:  0\n",
            "Epoch:  8 Batch:  1\n",
            "Epoch:  8 Batch:  2\n",
            "Epoch:  8 Batch:  3\n",
            "Epoch:  8 Batch:  4\n",
            "Epoch:  8 Batch:  5\n",
            "Epoch:  8 Batch:  6\n",
            "Epoch:  8 Batch:  7\n",
            "Epoch:  8 Batch:  8\n",
            "Epoch:  8 Batch:  9\n",
            "Epoch:  8 Batch:  10\n",
            "Epoch:  8 Batch:  11\n",
            "Epoch:  8 Batch:  12\n",
            "Epoch:  8 Batch:  13\n",
            "Epoch:  8 Batch:  14\n",
            "Epoch:  8 Batch:  15\n",
            "Epoch:  8 Batch:  16\n",
            "Epoch:  8 Batch:  17\n",
            "Epoch:  8 Batch:  18\n",
            "Epoch:  8 Batch:  19\n",
            "Epoch:  9 Batch:  0\n",
            "Epoch:  9 Batch:  1\n",
            "Epoch:  9 Batch:  2\n",
            "Epoch:  9 Batch:  3\n",
            "Epoch:  9 Batch:  4\n",
            "Epoch:  9 Batch:  5\n",
            "Epoch:  9 Batch:  6\n",
            "Epoch:  9 Batch:  7\n",
            "Epoch:  9 Batch:  8\n",
            "Epoch:  9 Batch:  9\n",
            "Epoch:  9 Batch:  10\n",
            "Epoch:  9 Batch:  11\n",
            "Epoch:  9 Batch:  12\n",
            "Epoch:  9 Batch:  13\n",
            "Epoch:  9 Batch:  14\n",
            "Epoch:  9 Batch:  15\n",
            "Epoch:  9 Batch:  16\n",
            "Epoch:  9 Batch:  17\n",
            "Epoch:  9 Batch:  18\n",
            "Epoch:  9 Batch:  19\n",
            "Training accuracy:   75.9%.\n",
            "Validation accuracy: 71.9%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Fine Tuning:\")\n",
        "test_model(alexNet_fineTuning, testloader)\n",
        "\n",
        "print(\"\\nFeature Extraction:\")\n",
        "test_model(alexNet_featureExtraction, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROkUFpzrGb0P",
        "outputId": "121feb38-6519-4871-aa5c-6ba111be3066"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine Tuning:\n",
            "Test accuracy: 62.1%.\n",
            "\n",
            "Feature Extraction:\n",
            "Test accuracy: 71.2%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "trainset_MNIST_big = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainset_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000)))\n",
        "\n",
        "trainloader_MNIST = torch.utils.data.DataLoader(trainset_MNIST, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "val_set_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000, 20000)))\n",
        "val_loader_MNIST = torch.utils.data.DataLoader(val_set_MNIST, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "                                          \n",
        "testset_MNIST = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader_MNIST = torch.utils.data.DataLoader(testset_MNIST, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "OxQ2IvovGdDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6041e23f-3c17-4ed1-fbd9-f7e011b1ca87"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 79593741.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 96986143.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 20510430.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4604913.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chose ResNet-18 as CNN model\n",
        "resnet = torchvision.models.resnet18(pretrained= False)\n",
        "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "# optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qs0dmaoGeO0",
        "outputId": "28335dbd-8704-4e5c-c38b-f71ca31cbd97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet=resnet.cuda()"
      ],
      "metadata": {
        "id": "WlwPJxwuCLUM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trained the model on MNIST data\n",
        "trained_resnet = train_model(resnet, criterion, optimizer, trainloader_MNIST, val_loader_MNIST, num_epochs=10)\n",
        "test_model(trained_resnet, testloader_MNIST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt9pEMYWGfQP",
        "outputId": "dd9e093c-f905-40b0-e125-0f25162bb1fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0 Batch:  0\n",
            "Epoch:  0 Batch:  1\n",
            "Epoch:  0 Batch:  2\n",
            "Epoch:  0 Batch:  3\n",
            "Epoch:  0 Batch:  4\n",
            "Epoch:  0 Batch:  5\n",
            "Epoch:  0 Batch:  6\n",
            "Epoch:  0 Batch:  7\n",
            "Epoch:  0 Batch:  8\n",
            "Epoch:  0 Batch:  9\n",
            "Epoch:  0 Batch:  10\n",
            "Epoch:  0 Batch:  11\n",
            "Epoch:  0 Batch:  12\n",
            "Epoch:  0 Batch:  13\n",
            "Epoch:  0 Batch:  14\n",
            "Epoch:  0 Batch:  15\n",
            "Epoch:  0 Batch:  16\n",
            "Epoch:  0 Batch:  17\n",
            "Epoch:  0 Batch:  18\n",
            "Epoch:  0 Batch:  19\n",
            "Epoch:  1 Batch:  0\n",
            "Epoch:  1 Batch:  1\n",
            "Epoch:  1 Batch:  2\n",
            "Epoch:  1 Batch:  3\n",
            "Epoch:  1 Batch:  4\n",
            "Epoch:  1 Batch:  5\n",
            "Epoch:  1 Batch:  6\n",
            "Epoch:  1 Batch:  7\n",
            "Epoch:  1 Batch:  8\n",
            "Epoch:  1 Batch:  9\n",
            "Epoch:  1 Batch:  10\n",
            "Epoch:  1 Batch:  11\n",
            "Epoch:  1 Batch:  12\n",
            "Epoch:  1 Batch:  13\n",
            "Epoch:  1 Batch:  14\n",
            "Epoch:  1 Batch:  15\n",
            "Epoch:  1 Batch:  16\n",
            "Epoch:  1 Batch:  17\n",
            "Epoch:  1 Batch:  18\n",
            "Epoch:  1 Batch:  19\n",
            "Epoch:  2 Batch:  0\n",
            "Epoch:  2 Batch:  1\n",
            "Epoch:  2 Batch:  2\n",
            "Epoch:  2 Batch:  3\n",
            "Epoch:  2 Batch:  4\n",
            "Epoch:  2 Batch:  5\n",
            "Epoch:  2 Batch:  6\n",
            "Epoch:  2 Batch:  7\n",
            "Epoch:  2 Batch:  8\n",
            "Epoch:  2 Batch:  9\n",
            "Epoch:  2 Batch:  10\n",
            "Epoch:  2 Batch:  11\n",
            "Epoch:  2 Batch:  12\n",
            "Epoch:  2 Batch:  13\n",
            "Epoch:  2 Batch:  14\n",
            "Epoch:  2 Batch:  15\n",
            "Epoch:  2 Batch:  16\n",
            "Epoch:  2 Batch:  17\n",
            "Epoch:  2 Batch:  18\n",
            "Epoch:  2 Batch:  19\n",
            "Epoch:  3 Batch:  0\n",
            "Epoch:  3 Batch:  1\n",
            "Epoch:  3 Batch:  2\n",
            "Epoch:  3 Batch:  3\n",
            "Epoch:  3 Batch:  4\n",
            "Epoch:  3 Batch:  5\n",
            "Epoch:  3 Batch:  6\n",
            "Epoch:  3 Batch:  7\n",
            "Epoch:  3 Batch:  8\n",
            "Epoch:  3 Batch:  9\n",
            "Epoch:  3 Batch:  10\n",
            "Epoch:  3 Batch:  11\n",
            "Epoch:  3 Batch:  12\n",
            "Epoch:  3 Batch:  13\n",
            "Epoch:  3 Batch:  14\n",
            "Epoch:  3 Batch:  15\n",
            "Epoch:  3 Batch:  16\n",
            "Epoch:  3 Batch:  17\n",
            "Epoch:  3 Batch:  18\n",
            "Epoch:  3 Batch:  19\n",
            "Epoch:  4 Batch:  0\n",
            "Epoch:  4 Batch:  1\n",
            "Epoch:  4 Batch:  2\n",
            "Epoch:  4 Batch:  3\n",
            "Epoch:  4 Batch:  4\n",
            "Epoch:  4 Batch:  5\n",
            "Epoch:  4 Batch:  6\n",
            "Epoch:  4 Batch:  7\n",
            "Epoch:  4 Batch:  8\n",
            "Epoch:  4 Batch:  9\n",
            "Epoch:  4 Batch:  10\n",
            "Epoch:  4 Batch:  11\n",
            "Epoch:  4 Batch:  12\n",
            "Epoch:  4 Batch:  13\n",
            "Epoch:  4 Batch:  14\n",
            "Epoch:  4 Batch:  15\n",
            "Epoch:  4 Batch:  16\n",
            "Epoch:  4 Batch:  17\n",
            "Epoch:  4 Batch:  18\n",
            "Epoch:  4 Batch:  19\n",
            "Epoch:  5 Batch:  0\n",
            "Epoch:  5 Batch:  1\n",
            "Epoch:  5 Batch:  2\n",
            "Epoch:  5 Batch:  3\n",
            "Epoch:  5 Batch:  4\n",
            "Epoch:  5 Batch:  5\n",
            "Epoch:  5 Batch:  6\n",
            "Epoch:  5 Batch:  7\n",
            "Epoch:  5 Batch:  8\n",
            "Epoch:  5 Batch:  9\n",
            "Epoch:  5 Batch:  10\n",
            "Epoch:  5 Batch:  11\n",
            "Epoch:  5 Batch:  12\n",
            "Epoch:  5 Batch:  13\n",
            "Epoch:  5 Batch:  14\n",
            "Epoch:  5 Batch:  15\n",
            "Epoch:  5 Batch:  16\n",
            "Epoch:  5 Batch:  17\n",
            "Epoch:  5 Batch:  18\n",
            "Epoch:  5 Batch:  19\n",
            "Epoch:  6 Batch:  0\n",
            "Epoch:  6 Batch:  1\n",
            "Epoch:  6 Batch:  2\n",
            "Epoch:  6 Batch:  3\n",
            "Epoch:  6 Batch:  4\n",
            "Epoch:  6 Batch:  5\n",
            "Epoch:  6 Batch:  6\n",
            "Epoch:  6 Batch:  7\n",
            "Epoch:  6 Batch:  8\n",
            "Epoch:  6 Batch:  9\n",
            "Epoch:  6 Batch:  10\n",
            "Epoch:  6 Batch:  11\n",
            "Epoch:  6 Batch:  12\n",
            "Epoch:  6 Batch:  13\n",
            "Epoch:  6 Batch:  14\n",
            "Epoch:  6 Batch:  15\n",
            "Epoch:  6 Batch:  16\n",
            "Epoch:  6 Batch:  17\n",
            "Epoch:  6 Batch:  18\n",
            "Epoch:  6 Batch:  19\n",
            "Epoch:  7 Batch:  0\n",
            "Epoch:  7 Batch:  1\n",
            "Epoch:  7 Batch:  2\n",
            "Epoch:  7 Batch:  3\n",
            "Epoch:  7 Batch:  4\n",
            "Epoch:  7 Batch:  5\n",
            "Epoch:  7 Batch:  6\n",
            "Epoch:  7 Batch:  7\n",
            "Epoch:  7 Batch:  8\n",
            "Epoch:  7 Batch:  9\n",
            "Epoch:  7 Batch:  10\n",
            "Epoch:  7 Batch:  11\n",
            "Epoch:  7 Batch:  12\n",
            "Epoch:  7 Batch:  13\n",
            "Epoch:  7 Batch:  14\n",
            "Epoch:  7 Batch:  15\n",
            "Epoch:  7 Batch:  16\n",
            "Epoch:  7 Batch:  17\n",
            "Epoch:  7 Batch:  18\n",
            "Epoch:  7 Batch:  19\n",
            "Epoch:  8 Batch:  0\n",
            "Epoch:  8 Batch:  1\n",
            "Epoch:  8 Batch:  2\n",
            "Epoch:  8 Batch:  3\n",
            "Epoch:  8 Batch:  4\n",
            "Epoch:  8 Batch:  5\n",
            "Epoch:  8 Batch:  6\n",
            "Epoch:  8 Batch:  7\n",
            "Epoch:  8 Batch:  8\n",
            "Epoch:  8 Batch:  9\n",
            "Epoch:  8 Batch:  10\n",
            "Epoch:  8 Batch:  11\n",
            "Epoch:  8 Batch:  12\n",
            "Epoch:  8 Batch:  13\n",
            "Epoch:  8 Batch:  14\n",
            "Epoch:  8 Batch:  15\n",
            "Epoch:  8 Batch:  16\n",
            "Epoch:  8 Batch:  17\n",
            "Epoch:  8 Batch:  18\n",
            "Epoch:  8 Batch:  19\n",
            "Epoch:  9 Batch:  0\n",
            "Epoch:  9 Batch:  1\n",
            "Epoch:  9 Batch:  2\n",
            "Epoch:  9 Batch:  3\n",
            "Epoch:  9 Batch:  4\n",
            "Epoch:  9 Batch:  5\n",
            "Epoch:  9 Batch:  6\n",
            "Epoch:  9 Batch:  7\n",
            "Epoch:  9 Batch:  8\n",
            "Epoch:  9 Batch:  9\n",
            "Epoch:  9 Batch:  10\n",
            "Epoch:  9 Batch:  11\n",
            "Epoch:  9 Batch:  12\n",
            "Epoch:  9 Batch:  13\n",
            "Epoch:  9 Batch:  14\n",
            "Epoch:  9 Batch:  15\n",
            "Epoch:  9 Batch:  16\n",
            "Epoch:  9 Batch:  17\n",
            "Epoch:  9 Batch:  18\n",
            "Epoch:  9 Batch:  19\n",
            "Training accuracy:   99.6%.\n",
            "Validation accuracy: 97.6%.\n",
            "Test accuracy: 97.6%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "all_svhn_train_data = torchvision.datasets.SVHN(root='./data', split= 'train',\n",
        "                                        download=True, transform=transform)\n",
        "all_svhn_test_data = torchvision.datasets.SVHN(root='./data', split= 'test',\n",
        "                                        download=True, transform=transform)\n",
        "svhn_train_set = torch.utils.data.Subset(all_svhn_train_data,list(range(10000)))\n",
        "svhn_val_set  = torch.utils.data.Subset(all_svhn_train_data,list(range(10000, 20000)))\n",
        "svhn_test_set  = torch.utils.data.Subset(all_svhn_test_data,list(range(10000)))\n",
        "\n",
        "svhn_train_loader = torch.utils.data.DataLoader(svhn_train_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "svhn_val_loader = torch.utils.data.DataLoader(svhn_val_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "svhn_test_loader = torch.utils.data.DataLoader(svhn_test_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFmWfe3FGg8C",
        "outputId": "0ec3cb2b-f556-470d-d6f0-b8976a5086c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:11<00:00, 15210779.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64275384/64275384 [00:06<00:00, 10587969.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "trained_resnet = trained_resnet.cuda()\n",
        "print(\"MNIST trained Resnet on SVHN dataset:\")\n",
        "test_model(trained_resnet, svhn_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L72ex8wOGiUj",
        "outputId": "5b71be53-720c-4646-d1bd-c76aef6d2447"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST trained Resnet on SVHN dataset:\n",
            "Test accuracy: 10.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_resnet_fe = trained_resnet \n",
        "\n",
        "# FREEZE all old params\n",
        "for param in trained_resnet_fe.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# new layer\n",
        "num_ftrs = trained_resnet_fe.fc.in_features\n",
        "trained_resnet_fe.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# find the paramaters we want to update during training\n",
        "params_to_update = []\n",
        "for param in trained_resnet_fe.parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "# Define our loss function\n",
        "criterion_fe = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define our optimizer\n",
        "optimizer_fe = torch.optim.Adam(params_to_update, lr=0.001)"
      ],
      "metadata": {
        "id": "kjmK3wKGGjnq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_resnet_fe=trained_resnet_fe.cuda()"
      ],
      "metadata": {
        "id": "k89MXf8iCRR9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the training step\n",
        "train_model(trained_resnet_fe, criterion_fe, optimizer_fe, svhn_train_loader, svhn_val_loader, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpIQx42jGkxi",
        "outputId": "3afb5efe-188d-4ff0-e429-184da8d07c01"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0 Batch:  0\n",
            "Epoch:  0 Batch:  1\n",
            "Epoch:  0 Batch:  2\n",
            "Epoch:  0 Batch:  3\n",
            "Epoch:  0 Batch:  4\n",
            "Epoch:  0 Batch:  5\n",
            "Epoch:  0 Batch:  6\n",
            "Epoch:  0 Batch:  7\n",
            "Epoch:  0 Batch:  8\n",
            "Epoch:  0 Batch:  9\n",
            "Epoch:  0 Batch:  10\n",
            "Epoch:  0 Batch:  11\n",
            "Epoch:  0 Batch:  12\n",
            "Epoch:  0 Batch:  13\n",
            "Epoch:  0 Batch:  14\n",
            "Epoch:  0 Batch:  15\n",
            "Epoch:  0 Batch:  16\n",
            "Epoch:  0 Batch:  17\n",
            "Epoch:  0 Batch:  18\n",
            "Epoch:  0 Batch:  19\n",
            "Epoch:  1 Batch:  0\n",
            "Epoch:  1 Batch:  1\n",
            "Epoch:  1 Batch:  2\n",
            "Epoch:  1 Batch:  3\n",
            "Epoch:  1 Batch:  4\n",
            "Epoch:  1 Batch:  5\n",
            "Epoch:  1 Batch:  6\n",
            "Epoch:  1 Batch:  7\n",
            "Epoch:  1 Batch:  8\n",
            "Epoch:  1 Batch:  9\n",
            "Epoch:  1 Batch:  10\n",
            "Epoch:  1 Batch:  11\n",
            "Epoch:  1 Batch:  12\n",
            "Epoch:  1 Batch:  13\n",
            "Epoch:  1 Batch:  14\n",
            "Epoch:  1 Batch:  15\n",
            "Epoch:  1 Batch:  16\n",
            "Epoch:  1 Batch:  17\n",
            "Epoch:  1 Batch:  18\n",
            "Epoch:  1 Batch:  19\n",
            "Epoch:  2 Batch:  0\n",
            "Epoch:  2 Batch:  1\n",
            "Epoch:  2 Batch:  2\n",
            "Epoch:  2 Batch:  3\n",
            "Epoch:  2 Batch:  4\n",
            "Epoch:  2 Batch:  5\n",
            "Epoch:  2 Batch:  6\n",
            "Epoch:  2 Batch:  7\n",
            "Epoch:  2 Batch:  8\n",
            "Epoch:  2 Batch:  9\n",
            "Epoch:  2 Batch:  10\n",
            "Epoch:  2 Batch:  11\n",
            "Epoch:  2 Batch:  12\n",
            "Epoch:  2 Batch:  13\n",
            "Epoch:  2 Batch:  14\n",
            "Epoch:  2 Batch:  15\n",
            "Epoch:  2 Batch:  16\n",
            "Epoch:  2 Batch:  17\n",
            "Epoch:  2 Batch:  18\n",
            "Epoch:  2 Batch:  19\n",
            "Epoch:  3 Batch:  0\n",
            "Epoch:  3 Batch:  1\n",
            "Epoch:  3 Batch:  2\n",
            "Epoch:  3 Batch:  3\n",
            "Epoch:  3 Batch:  4\n",
            "Epoch:  3 Batch:  5\n",
            "Epoch:  3 Batch:  6\n",
            "Epoch:  3 Batch:  7\n",
            "Epoch:  3 Batch:  8\n",
            "Epoch:  3 Batch:  9\n",
            "Epoch:  3 Batch:  10\n",
            "Epoch:  3 Batch:  11\n",
            "Epoch:  3 Batch:  12\n",
            "Epoch:  3 Batch:  13\n",
            "Epoch:  3 Batch:  14\n",
            "Epoch:  3 Batch:  15\n",
            "Epoch:  3 Batch:  16\n",
            "Epoch:  3 Batch:  17\n",
            "Epoch:  3 Batch:  18\n",
            "Epoch:  3 Batch:  19\n",
            "Epoch:  4 Batch:  0\n",
            "Epoch:  4 Batch:  1\n",
            "Epoch:  4 Batch:  2\n",
            "Epoch:  4 Batch:  3\n",
            "Epoch:  4 Batch:  4\n",
            "Epoch:  4 Batch:  5\n",
            "Epoch:  4 Batch:  6\n",
            "Epoch:  4 Batch:  7\n",
            "Epoch:  4 Batch:  8\n",
            "Epoch:  4 Batch:  9\n",
            "Epoch:  4 Batch:  10\n",
            "Epoch:  4 Batch:  11\n",
            "Epoch:  4 Batch:  12\n",
            "Epoch:  4 Batch:  13\n",
            "Epoch:  4 Batch:  14\n",
            "Epoch:  4 Batch:  15\n",
            "Epoch:  4 Batch:  16\n",
            "Epoch:  4 Batch:  17\n",
            "Epoch:  4 Batch:  18\n",
            "Epoch:  4 Batch:  19\n",
            "Epoch:  5 Batch:  0\n",
            "Epoch:  5 Batch:  1\n",
            "Epoch:  5 Batch:  2\n",
            "Epoch:  5 Batch:  3\n",
            "Epoch:  5 Batch:  4\n",
            "Epoch:  5 Batch:  5\n",
            "Epoch:  5 Batch:  6\n",
            "Epoch:  5 Batch:  7\n",
            "Epoch:  5 Batch:  8\n",
            "Epoch:  5 Batch:  9\n",
            "Epoch:  5 Batch:  10\n",
            "Epoch:  5 Batch:  11\n",
            "Epoch:  5 Batch:  12\n",
            "Epoch:  5 Batch:  13\n",
            "Epoch:  5 Batch:  14\n",
            "Epoch:  5 Batch:  15\n",
            "Epoch:  5 Batch:  16\n",
            "Epoch:  5 Batch:  17\n",
            "Epoch:  5 Batch:  18\n",
            "Epoch:  5 Batch:  19\n",
            "Epoch:  6 Batch:  0\n",
            "Epoch:  6 Batch:  1\n",
            "Epoch:  6 Batch:  2\n",
            "Epoch:  6 Batch:  3\n",
            "Epoch:  6 Batch:  4\n",
            "Epoch:  6 Batch:  5\n",
            "Epoch:  6 Batch:  6\n",
            "Epoch:  6 Batch:  7\n",
            "Epoch:  6 Batch:  8\n",
            "Epoch:  6 Batch:  9\n",
            "Epoch:  6 Batch:  10\n",
            "Epoch:  6 Batch:  11\n",
            "Epoch:  6 Batch:  12\n",
            "Epoch:  6 Batch:  13\n",
            "Epoch:  6 Batch:  14\n",
            "Epoch:  6 Batch:  15\n",
            "Epoch:  6 Batch:  16\n",
            "Epoch:  6 Batch:  17\n",
            "Epoch:  6 Batch:  18\n",
            "Epoch:  6 Batch:  19\n",
            "Epoch:  7 Batch:  0\n",
            "Epoch:  7 Batch:  1\n",
            "Epoch:  7 Batch:  2\n",
            "Epoch:  7 Batch:  3\n",
            "Epoch:  7 Batch:  4\n",
            "Epoch:  7 Batch:  5\n",
            "Epoch:  7 Batch:  6\n",
            "Epoch:  7 Batch:  7\n",
            "Epoch:  7 Batch:  8\n",
            "Epoch:  7 Batch:  9\n",
            "Epoch:  7 Batch:  10\n",
            "Epoch:  7 Batch:  11\n",
            "Epoch:  7 Batch:  12\n",
            "Epoch:  7 Batch:  13\n",
            "Epoch:  7 Batch:  14\n",
            "Epoch:  7 Batch:  15\n",
            "Epoch:  7 Batch:  16\n",
            "Epoch:  7 Batch:  17\n",
            "Epoch:  7 Batch:  18\n",
            "Epoch:  7 Batch:  19\n",
            "Epoch:  8 Batch:  0\n",
            "Epoch:  8 Batch:  1\n",
            "Epoch:  8 Batch:  2\n",
            "Epoch:  8 Batch:  3\n",
            "Epoch:  8 Batch:  4\n",
            "Epoch:  8 Batch:  5\n",
            "Epoch:  8 Batch:  6\n",
            "Epoch:  8 Batch:  7\n",
            "Epoch:  8 Batch:  8\n",
            "Epoch:  8 Batch:  9\n",
            "Epoch:  8 Batch:  10\n",
            "Epoch:  8 Batch:  11\n",
            "Epoch:  8 Batch:  12\n",
            "Epoch:  8 Batch:  13\n",
            "Epoch:  8 Batch:  14\n",
            "Epoch:  8 Batch:  15\n",
            "Epoch:  8 Batch:  16\n",
            "Epoch:  8 Batch:  17\n",
            "Epoch:  8 Batch:  18\n",
            "Epoch:  8 Batch:  19\n",
            "Epoch:  9 Batch:  0\n",
            "Epoch:  9 Batch:  1\n",
            "Epoch:  9 Batch:  2\n",
            "Epoch:  9 Batch:  3\n",
            "Epoch:  9 Batch:  4\n",
            "Epoch:  9 Batch:  5\n",
            "Epoch:  9 Batch:  6\n",
            "Epoch:  9 Batch:  7\n",
            "Epoch:  9 Batch:  8\n",
            "Epoch:  9 Batch:  9\n",
            "Epoch:  9 Batch:  10\n",
            "Epoch:  9 Batch:  11\n",
            "Epoch:  9 Batch:  12\n",
            "Epoch:  9 Batch:  13\n",
            "Epoch:  9 Batch:  14\n",
            "Epoch:  9 Batch:  15\n",
            "Epoch:  9 Batch:  16\n",
            "Epoch:  9 Batch:  17\n",
            "Epoch:  9 Batch:  18\n",
            "Epoch:  9 Batch:  19\n",
            "Training accuracy:   28.2%.\n",
            "Validation accuracy: 25.1%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Feature Extraction of MNIST-trained Resnet on SVHN dataset:\")\n",
        "test_model(trained_resnet_fe, svhn_test_loader)"
      ],
      "metadata": {
        "id": "Be9I_KwrGm2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20d7f77-5cc4-4735-dd7d-b313683a305d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Extraction of MNIST-trained Resnet on SVHN dataset:\n",
            "Test accuracy: 25.8%.\n"
          ]
        }
      ]
    }
  ]
}