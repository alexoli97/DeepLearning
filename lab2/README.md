# Lab 2 - Loss Functions and Evaluation Metrics in CNNs

## Overview
Lab 2 focuses on understanding and manually calculating various loss functions and evaluation metrics crucial in the training and performance assessment of Convolutional Neural Networks (CNNs). The accompanying Colab Notebook provides practical examples and exercises.

## Prerequisites
- Basic understanding of CNNs and their evaluation metrics.
- Familiarity with Python and basic mathematical operations.

## Theory Part

### 1. Loss Functions
- **Objective**: Calculate different types of loss functions manually.
- **Key Loss Functions**:
  - Cross-Entropy Loss
  - Mean Squared Error Loss
  - Hinge Loss (SVM Loss)
- **Example Calculation**: Using given prediction and ground truth vectors to calculate each loss function.

### 2. Evaluation Metrics
- **Objective**: Understand the importance and calculation of different evaluation metrics.
- **Key Concepts**:
  - Situations where accuracy isn't a good measure.
  - Comparison between Jaccard Index and F1-Measure.
  - Computation of Jaccard Index, Precision, Recall, F1-measure for multi-class and multi-label scenarios.
  - Calculation of global Exact Match metric and its implications.

## Practical Part
The Colab Notebook attached contains code snippets and exercises to practically implement the concepts covered in the theory part.

## Instructions
1. Review the theory part to understand the fundamental concepts.
2. Perform the calculations as instructed in the exercises.
3. Execute the code in the Colab Notebook to see practical implementations.
4. Compare theoretical calculations with practical outcomes for a comprehensive understanding.

## Additional Resources
- [Deep Learning Book, Section 3.13](#)
- [CS231n Lecture Notes](#)
- [Wikipedia: Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index)
- [Wikipedia: Multi-label Classification](https://en.wikipedia.org/wiki/Multi-label_classification)
- [Wikipedia: Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)

## Contribution
Contributions to this guide are welcome, especially in terms of additional exercises, examples, or resources.
